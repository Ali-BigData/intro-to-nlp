{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "nn_bow_classifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/intro-to-nlp/blob/master/nn_bow_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJgSQnTr5hKs"
      },
      "source": [
        "# Bag-of-words document classification\n",
        "\n",
        "* BoW is the simplest way to do classification: Feature vector goes in, decision falls out.\n",
        "\n",
        "* Feature vector: a vector with as many dimensions as we have unique features, and a non-zero value set for every feature present in our example\n",
        "* Binary features: 1/0\n",
        "\n",
        "In the following we work with the IMDB data, have a look on [how to read it in](read_imdb.ipynb). Here we just read the ready data in.\n",
        "\n",
        "# IMDB data\n",
        "\n",
        "* Familiar data\n",
        "* Input vectorized as before\n",
        "* But now we will also have to turn class labels into integers and back explicitly so we can use Keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxbv7By-57T4",
        "outputId": "7052f4ec-f741-471f-ea2d-a0e448dfe071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget -nc https://github.com/TurkuNLP/intro-to-nlp/raw/master/Data/imdb_train.json"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-08 07:34:14--  https://github.com/TurkuNLP/intro-to-nlp/raw/master/Data/imdb_train.json\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/TurkuNLP/intro-to-nlp/master/Data/imdb_train.json [following]\n",
            "--2021-01-08 07:34:15--  https://raw.githubusercontent.com/TurkuNLP/intro-to-nlp/master/Data/imdb_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33944099 (32M) [text/plain]\n",
            "Saving to: ‘imdb_train.json’\n",
            "\n",
            "imdb_train.json     100%[===================>]  32.37M  58.3MB/s    in 0.6s    \n",
            "\n",
            "2021-01-08 07:34:15 (58.3 MB/s) - ‘imdb_train.json’ saved [33944099/33944099]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXG8Ca0e5hKz"
      },
      "source": [
        "import json\n",
        "import random\n",
        "with open(\"imdb_train.json\") as f:\n",
        "    data=json.load(f)\n",
        "random.shuffle(data) #play it safe!\n",
        "\n",
        "texts=[one_example[\"text\"] for one_example in data]\n",
        "labels=[one_example[\"class\"] for one_example in data]\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amrLFpve5hK0",
        "outputId": "b6eb444e-170a-4f0b-893c-4feb3d424542",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_texts, dev_texts, train_labels, dev_labels=train_test_split(texts,labels,test_size=0.2)\n",
        "vectorizer=CountVectorizer(max_features=100000,binary=True,ngram_range=(1,1))\n",
        "feature_matrix_train=vectorizer.fit_transform(train_texts)\n",
        "feature_matrix_dev=vectorizer.transform(dev_texts)\n",
        "\n",
        "print(\"shape=\",feature_matrix_train.shape)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape= (20000, 68509)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTsbLacCAAAo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def convert_sparse_matrix_to_sparse_tensor(X):\n",
        "    coo = X.tocoo()\n",
        "    indices = np.mat([coo.row, coo.col]).transpose()\n",
        "    return tf.sparse.reorder(tf.SparseTensor(indices, coo.data, coo.shape))\n",
        "\n",
        "feature_matrix_train_tf=convert_sparse_matrix_to_sparse_tensor(feature_matrix_train)\n",
        "feature_matrix_dev_tf=convert_sparse_matrix_to_sparse_tensor(feature_matrix_dev)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIluAddR5hK6"
      },
      "source": [
        "Now we have the feature matrix done! Next thing we need is the class labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE7xaPp65hK7",
        "outputId": "c1de90fa-23be-44bb-aeff-9c2884c2a6d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder=LabelEncoder() #Turns class labels into integers\n",
        "class_numbers_train=label_encoder.fit_transform(train_labels)\n",
        "class_numbers_dev=label_encoder.transform(dev_labels)\n",
        "\n",
        "print(\"class_numbers shape=\",class_numbers_train.shape)\n",
        "print(\"class labels\",label_encoder.classes_) #this will let us translate back from indices to labels"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class_numbers shape= (20000,)\n",
            "class labels ['neg' 'pos']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9Bo2pEq5hK8"
      },
      "source": [
        "* The data is ready :)\n",
        "\n",
        "We need to build the network now\n",
        "* Input\n",
        "* Hidden Dense layer with some kind of non-linearity, and a suitable number of nodes\n",
        "* Output Dense layer with the softmax activation (normalizes output to distribution) and as many nodes as there are classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLzFHV2d5hK8"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "\n",
        "example_count,feature_count=feature_matrix_train.shape #how many examples and features we've got?\n",
        "example_count2=class_numbers_train.shape[0]\n",
        "assert example_count==example_count2 #sanity check\n",
        "class_count=len(label_encoder.classes_) #How many classes we've got?\n",
        "\n",
        "#Build the network:\n",
        "inp=Input(shape=(feature_count,)) #Input layer\n",
        "hidden=Dense(200,activation=\"tanh\")(inp) #Hidden layer\n",
        "outp=Dense(class_count,activation=\"softmax\")(hidden) #Output layer\n",
        "model=Model(inputs=[inp], outputs=[outp])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyIYRRvE5hK9"
      },
      "source": [
        "...it's **this** simple...!\n",
        "\n",
        "Once the model is constructed it needs to be compiled, for that we need to know:\n",
        "* which optimizer we want to use (sgd is fine to begin with)\n",
        "* what is the loss (sparse_categorial_crossentropy for multiclass of the kind we have is the right choice)\n",
        "* which metrics to measure, accuracy is an okay choice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2uv181F5hK-"
      },
      "source": [
        "model.compile(optimizer=\"sgd\",loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl2XExJk5hK-"
      },
      "source": [
        "A compiled model can be fitted on data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzZbwpRG5hK-",
        "outputId": "bb078f5f-98b3-4931-df15-9b91011633e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "hist=model.fit(feature_matrix_train_tf,class_numbers_train,\\\n",
        "               validation_data=(feature_matrix_dev_tf,class_numbers_dev),\\\n",
        "               batch_size=100,verbose=1,epochs=10)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.6267 - accuracy: 0.7065 - val_loss: 0.4941 - val_accuracy: 0.8202\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.4732 - accuracy: 0.8220 - val_loss: 0.4173 - val_accuracy: 0.8362\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.4003 - accuracy: 0.8511 - val_loss: 0.3771 - val_accuracy: 0.8514\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3592 - accuracy: 0.8632 - val_loss: 0.3516 - val_accuracy: 0.8608\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.8709 - val_loss: 0.3344 - val_accuracy: 0.8660\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.3176 - accuracy: 0.8777 - val_loss: 0.3219 - val_accuracy: 0.8704\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.2935 - accuracy: 0.8882 - val_loss: 0.3122 - val_accuracy: 0.8718\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.2826 - accuracy: 0.8910 - val_loss: 0.3053 - val_accuracy: 0.8744\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.2712 - accuracy: 0.8947 - val_loss: 0.2991 - val_accuracy: 0.8780\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 1s 3ms/step - loss: 0.2656 - accuracy: 0.8988 - val_loss: 0.2942 - val_accuracy: 0.8810\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PkjpcL58e5X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbz1dBZI5hK_",
        "outputId": "11885c6f-3807-447a-946d-55d741bfa7af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(hist.history[\"val_accuracy\"])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.8202000260353088, 0.8361999988555908, 0.8514000177383423, 0.86080002784729, 0.8659999966621399, 0.8704000115394592, 0.8718000054359436, 0.8744000196456909, 0.878000020980835, 0.8809999823570251]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5ln4rnH5hLA"
      },
      "source": [
        "* We ran for 10 epochs of training\n",
        "* Made it to a decent accuracy on the validation data\n",
        "\n",
        "* But we do not have the model saved, so let's fix that and get the whole thing done\n",
        "* What constitutes a model (ie what we need to run the model on new data)\n",
        "  - The feature dictionary in the vectorizer\n",
        "  - The list of classes in their correct order\n",
        "  - The structure of the network\n",
        "  - The weights the network learned\n",
        "\n",
        "* Do all these things, and run again. This time we also increase the number of epochs, see what happens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtLKUWW45hLA",
        "outputId": "0e165f18-7380-45b5-b145-bd710e14df4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras import optimizers\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "def save_model(file_name,model,label_encoder,vectorizer):\n",
        "    \"\"\"Saves model structure and vocabularies\"\"\"\n",
        "    model_json = model.to_json()\n",
        "    with open(file_name+\".model.json\", \"w\") as f:\n",
        "        print(model_json,file=f)\n",
        "    with open(file_name+\".encoders.pickle\",\"wb\") as f:\n",
        "        pickle.dump((label_encoder,vectorizer),f)\n",
        "    #with open(file_name+\".vocabularies.json\",\"w\") as f:\n",
        "    #    classes=list(label_encoder.classes_)\n",
        "    #    vocab=dict(((str(w),int(idx)) for w,idx in vectorizer.vocabulary_.items())) #must turn numpy objects to python ones\n",
        "    #    json.dump((classes,vocab),f,indent=2)\n",
        "        \n",
        "example_count,feature_count=feature_matrix_train_tf.shape #how many examples and features we've got?\n",
        "example_count2=class_numbers_train.shape[0]\n",
        "assert example_count==example_count2 #sanity check\n",
        "class_count=len(label_encoder.classes_) #How many classes we've got?\n",
        "\n",
        "#Build the network:\n",
        "inp=Input(shape=(feature_count,)) #Input layer\n",
        "hidden=Dense(200,activation=\"tanh\")(inp) #Hidden layer\n",
        "outp=Dense(class_count,activation=\"softmax\")(hidden) #Output layer\n",
        "model=Model(inputs=[inp], outputs=[outp])\n",
        "\n",
        "# Let's try a different optimizer!\n",
        "opt=optimizers.Adam()\n",
        "model.compile(optimizer=opt,loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
        "\n",
        "# Save model and vocabularies, can be done before training\n",
        "os.makedirs(\"models\",exist_ok=True)\n",
        "save_model(\"models/imdb_bow\",model,label_encoder,vectorizer)\n",
        "# Callback function to save weights during training, if validation loss goes down\n",
        "save_cb=ModelCheckpoint(filepath=\"models/imdb_bow.weights.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "stop_cb=EarlyStopping(patience=2,verbose=1,restore_best_weights=True)\n",
        "hist=model.fit(feature_matrix_train_tf,class_numbers_train,\\\n",
        "               validation_data=(feature_matrix_dev_tf,class_numbers_dev),\\\n",
        "               batch_size=100,verbose=1,epochs=20,\\\n",
        "               callbacks=[save_cb,stop_cb])\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.3974 - accuracy: 0.8202 - val_loss: 0.2723 - val_accuracy: 0.8896\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.27227, saving model to models/imdb_bow.weights.h5\n",
            "Epoch 2/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0916 - accuracy: 0.9698 - val_loss: 0.3604 - val_accuracy: 0.8782\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.27227\n",
            "Epoch 3/20\n",
            "200/200 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9914 - val_loss: 0.4890 - val_accuracy: 0.8798\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.27227\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00003: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBKFuz2z5hLC",
        "outputId": "1915c2b6-06f1-478c-a1a7-f2d9991caf18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#Validation data used during training:\n",
        "val_instances,val_labels=feature_matrix_dev_tf,class_numbers_dev\n",
        "\n",
        "print(\"Network output=\",model.predict(val_instances))\n",
        "predictions=numpy.argmax(model.predict(val_instances),axis=1)\n",
        "print(\"Maximum class for each example=\",predictions)\n",
        "gold=val_labels\n",
        "conf_matrix=confusion_matrix(list(gold),list(predictions))\n",
        "print(\"Confusion matrix=\\n\",conf_matrix)\n",
        "\n",
        "gold_labels=label_encoder.inverse_transform(list(gold))\n",
        "predicted_labels=label_encoder.inverse_transform(list(predictions))\n",
        "#print(\"Gold labels=\",gold_labels)\n",
        "#print(\"Predicted labels=\",predicted_labels)\n",
        "print(classification_report(gold_labels,predicted_labels))\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network output= [[0.8699621  0.13003789]\n",
            " [0.00108381 0.99891627]\n",
            " [0.16914144 0.8308585 ]\n",
            " ...\n",
            " [0.6138316  0.38616842]\n",
            " [0.9706871  0.02931287]\n",
            " [0.9768312  0.02316885]]\n",
            "Maximum class for each example= [0 1 1 ... 0 0 0]\n",
            "Confusion matrix=\n",
            " [[2117  370]\n",
            " [ 182 2331]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.92      0.85      0.88      2487\n",
            "         pos       0.86      0.93      0.89      2513\n",
            "\n",
            "    accuracy                           0.89      5000\n",
            "   macro avg       0.89      0.89      0.89      5000\n",
            "weighted avg       0.89      0.89      0.89      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U691K9Gi5hLD"
      },
      "source": [
        "# Learning progress\n",
        "\n",
        "* The history object we get lets us inspect the accuracy during training\n",
        "* Remarks:\n",
        "  - Accuracy on training data keeps going up\n",
        "  - Accuracy on validation (test) data flattens out after a but over 10 epochs, we are learning very little past that point\n",
        "  - What we see is the network keeps overfitting on the training data to the end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOZMQI8_5hLE",
        "outputId": "ec2dd5c3-40df-456e-87bb-2ecb50fa10d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.ylim(0.55,1.0)\n",
        "plt.plot(hist.history[\"val_accuracy\"],label=\"Validation set accuracy\")\n",
        "plt.plot(hist.history[\"accuracy\"],label=\"Training set accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUH5yli05hLF"
      },
      "source": [
        "# Summary\n",
        "\n",
        "* We put together a program to train a neural network classifier for sentiment detector\n",
        "* We learned the necessary code/techniques to save models, and feed the training with data in just the right format\n",
        "* We observed the training across epochs\n",
        "* We saw how the classifier can be applied to various text classification problems\n",
        "* The IMDB sentiment classifier ended up at nearly 90% accuracy, the state of the art is about 95%, we got surprisingly far in few lines of code\n"
      ]
    }
  ]
}