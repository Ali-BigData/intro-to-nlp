{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence labeling\n",
    "\n",
    "* Many classification tasks produce a sequence of predictions, rather than a single prediction\n",
    "* In this lecture we have a look at these tasks, and try to understand what makes this setting special"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging\n",
    "\n",
    "![posfig](figs/pos_voita.png)\n",
    "![posfig](figs/pos_house.png)\n",
    "\n",
    "* Every word is assigned to its part-of-speech category\n",
    "* The number of categories is potentially quite large, in this case less than 20 though (You can see them [here](https://universaldependencies.org/u/pos/index.html) by the way)\n",
    "* POS tagging is often used as a pre-processing step\n",
    "* You can also use it to pick important words as features (nouns, verbs, etc)\n",
    "* Note the context-dependence of the tags\n",
    "  * `voita` can be a verb also, `voi` can be a noun also\n",
    "  * `house` can be a noun or a verb\n",
    "  * ...\n",
    "* The tags also have a dependence among each other\n",
    "  * Many sequences are impossible or at least highly unlikely, regardless of the input\n",
    "  * In English, having seen a determiner, the likely next tag is a noun or an adjective, and e.g. a verb is extremely unlikely\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named entity recognition\n",
    "\n",
    "![nerfig](figs/ner_demo.png)\n",
    "![nerfig](figs/ner_demo_en.png)\n",
    "\n",
    "\n",
    "* NER is usually cast as a sequence labeling problem\n",
    "* Entities are (typically) sequences of words, like `Turun Yliopisto` or `British Airways`\n",
    "* The type tells what kind of an entity we have. The list of types is usually quite restricted: `Person, Organization, Location, Product, Event, Date, Other` would be a typical list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIO-coding\n",
    "\n",
    "* NER and other similar tasks that involve locating multi-word entities are cast as classification of individual tokens into three groups of classes:\n",
    "\n",
    "* **B-category**: The token begins an entity of type `category`. For example `B-Person` or `B-Location`\n",
    "* **I-category**: The token continues an entity that is already started (with a `B-category`)\n",
    "* **O**: The token is not a part of any entity\n",
    "\n",
    "Here is an example from our [Finnish NER training data](https://github.com/TurkuNLP/turku-ner-corpus):\n",
    "\n",
    "```\n",
    "The\tB-PRO\n",
    "Garden\tI-PRO\n",
    "Collection\tI-PRO\n",
    "by\tO\n",
    "H&M\tB-ORG\n",
    "\n",
    "Viikonlopun\tO\n",
    "pyöritys\tO\n",
    "alkoi\tO\n",
    "H&M:n\tB-ORG\n",
    "järjestämällä\tO\n",
    "bloggaajabrunssilla\tO\n",
    "Helsingissä\tB-LOC\n",
    ".\tO\n",
    "```\n",
    "\n",
    "* `BIO-coding` is suitable for cases where you do not have entity nesting and overlaps\n",
    "* There are, once again, quite clear dependencies between labels regardless of the input:\n",
    "  * Exmaples of legal: `O B-Person O O`, `B-Person I-Person O O`, `B-Person B-Person`\n",
    "  * Examples of illegal: `B-Person O I-Person O`, `O O I-Person O O`, `O B-Person I-Event O`\n",
    "* Preferably, the classifier should be prevented from producing illegal BIO sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text segmentation\n",
    "\n",
    "* Text segmentation (splitting into tokens and sentences) is often carried out as sequence labeling\n",
    "* One would label every individual character as one of:\n",
    "  * token ends after this character\n",
    "  * sentence ends after this character\n",
    "  * inside token\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Is it you?\n",
    "\n",
    "I     inside\n",
    "s     token-break\n",
    "      token-break\n",
    "i     inside\n",
    "t     token-break\n",
    "      token-break\n",
    "y     inside\n",
    "o     inside\n",
    "u     token-break\n",
    "?     sentence-break\n",
    "```\n",
    "\n",
    "* **Note:** what, precisely, happens at spaces is somewhat implementation-dependent and you can do it in various ways, this is only one of the possibilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zoning\n",
    "\n",
    "* In many applications, one may want to separate text into zones\n",
    "    * scientific papers may need to be separated into backround, methods, results, citations\n",
    "    * patents can be separated into background and claims\n",
    "    * ...\n",
    "* The BIO coding is applicable also here\n",
    "    * perhaps the unit of classification are the whole sentences or even paragraphs, not words\n",
    "    * depends on task, ie can you expect a zone to change half-way through the sentence\n",
    "\n",
    "![zoningfig](figs/zones.gif)\n",
    "Figure from: https://www.cl.cam.ac.uk/~sht25/az.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
